I would like to build the backend portion of an automated data processing pipeline for astronomical data. The backend will utilise sqllite tables in a database called wombatpipeline. The first component of the pipeline will search a directory './data' and look for nights in subdirs. within each night subdir there could be 'Bias', 'Flat', 'Light' subdirs. within the Light dir there will be target subdirs. I want to record each (night,target) in a table 'target' as follows: date, target name, filter that was used, 'proc', 'apphot', 'submitted' which will be used later. If the (date,target name) already exists skip.

If a night dir exists with Bias and/or flats but no Light then ignore this night

If a night contains Lights, Biases and/or Flats then add to the table 'cal' as follows: date, calibration type, (if flat then what filter; if bias then null), number of images of this type. A Flat directory might have multiple filters present the filter is in the fits header. If multiple filters exist make a sub directory for each one e.g. FlatV, FlatB...

** Second Phase **

If a night contains more than 2 Flats of a given filter these should be scaled / normalised and median combined with sigma clipping to form mflat{filter name}.fits. If for some reason, there is a mflat{filter name}.fits already skip

If a night contains more than 2 Biases these should be median combined with sigma clipping to form mbias.fits. If mbias already exists skip.

** Third Phase **

Next we sweep over the target table. For all (night,target,filter) with proc_bias and proc_flat None (or 0) we locate the closest bias and flatfield (forwards or backwards in time) and then process the science data frames. If no appropriate calibration file can be found then proc_{cal type} = 'nocal'. We record the date of the bias frame in proc_BIAS, and the flat in proc_flat. We then plate solve using ASTAP (in Applications) with -update -analyse snr_min. I think we also should allow two '-fov's if it fails 10, 30 degrees. Report details/errors in WCS record to table 'WCS'.

** Fourth Phase **
Now we search AAVSO VSX for the target name. From the target information we implement the calculations for time and airmass as per aij coordinate converter. We then obtain the comparison stars in the field (centered on the target) with field of view the extent of the image (from its fits header). The comparison stars come from a query of AAVSO VSP - which is not working today :P
If no comp stars can be found set apphot to 'nocomps'

** Fifth Phase ** 

On pause due to AAVSO VSP down

Of the VSP comp stars in the field reject those that do not lie on the extent of the image (use the fits header for this). Reject comp stars that are 1.5 mag brighter than the variable star MinMagV and 1.5 magnitude fainter than the variable's maxMagV. If none remain flag error apphot='nocomps'

For all targets with apphot null, go to the first file and locate a star with peak intensity between 30000 - 5000 counts fit a PSF profile to the star - determine a goodness-of-fit. If very bad flag error apphot='badpsf'. Otherwise determine the star aperture and the sky annulus for aperture photometry. 

Find the comp star that is closest spatially and in magnitude to the variable. This has the special status 'T2', the variable star is 'T1', and the comp stars are C3..N.

Using the RA,Dec of the list of T1,T2,C3...use the image header to determine the image x,y. On that x,y place the apertures defined above and produce the aperture photometry. Do this for each image in the night,target,filter set. G5903.00430_20251015_phot.tbl shows the format required and the various columns like airmass and HJD.

** Phase Six **
use the methods of ../stdphot to transform the mags to standards mags. If succeeds set apphot = 'validate'

User validation phase: for each target,night,filter with apphot = 'validate' Produce a lightcurve for T1 & T2 (lower mags at the top)